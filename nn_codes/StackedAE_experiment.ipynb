{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sparse_ae import *\n",
    "import scipy.misc\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "m = StackedAE(img_path='/data/gabriel/LVseg/dataset_img/cropped/img/',\n",
    "              label_path='/data/gabriel/LVseg/dataset_img/cropped/label/',test_train_dst='/data/gabriel/LVseg/dataset_img/cropped/test_train_seg')\n",
    "#tt = Variable(torch.Tensor(1,4096))\n",
    "#tt2 = Variable(torch.Tensor(1,100))\n",
    "#tt3 = Variable(torch.Tensor(1,100))\n",
    "\n",
    "#count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1\n",
      "fc2\n",
      "fc3\n"
     ]
    }
   ],
   "source": [
    "count= 0\n",
    "for name,module in m.named_children():\n",
    "    print(name)\n",
    "    module.requires_grad=False\n",
    "#    count+=1\n",
    "#    print('           ',count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on StackedAE in module sparse_ae object:\n",
      "\n",
      "class StackedAE(torch.nn.modules.module.Module)\n",
      " |  Method resolution order:\n",
      " |      StackedAE\n",
      " |      torch.nn.modules.module.Module\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, img_path, label_path, gpu=0, n_in=64, n_h=100, n_out=64, test_fraction=0, lr=0.01, test_train_dst='/data/gabriel/LVseg/dataset_img/data_seg', b_size=1000)\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |  \n",
      " |  hidden1(self, x)\n",
      " |  \n",
      " |  hidden2(self, x)\n",
      " |  \n",
      " |  out_at_layer(self, inp, L)\n",
      " |  \n",
      " |  target_layer(self, x)\n",
      " |  \n",
      " |  transform(self, rand=False, mean=0, sd=1)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |  \n",
      " |  cpu(self, device_id=None)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |  \n",
      " |  cuda(self, device_id=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device_id (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all parameters and buffers to double datatype.\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on modules such as Dropout or BatchNorm.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all parameters and buffers to float datatype.\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all parameters and buffers to half datatype.\n",
      " |  \n",
      " |  load_state_dict(self, state_dict)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. The keys of :attr:`state_dict` must\n",
      " |      exactly match the keys returned by this module's :func:`state_dict()`\n",
      " |      function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): A dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |          >>>     print(idx, '->', m)\n",
      " |          0 -> Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          )\n",
      " |          1 -> Linear (2 -> 2)\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |          >>>     print(idx, '->', m)\n",
      " |          0 -> ('', Sequential (\n",
      " |            (0): Linear (2 -> 2)\n",
      " |            (1): Linear (2 -> 2)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear (2 -> 2))\n",
      " |  \n",
      " |  named_parameters(self, memo=None, prefix='')\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, memo=None)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      This function returns a handle with a method ``handle.remove()``\n",
      " |      that removes the hook from the module.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time :func:`forward` computes an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None\n",
      " |      \n",
      " |      The hook should not modify the input or output.\n",
      " |      This function returns a handle with a method ``handle.remove()``\n",
      " |      that removes the hook from the module.\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='')\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Example:\n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on modules such as Dropout or BatchNorm.\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in m.modules():\n",
    "    print(help(i))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "Variable containing:\n",
      " 200.5456\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1\n",
      "Variable containing:\n",
      " 106.2296\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2\n",
      "Variable containing:\n",
      " 84.8429\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "torch.Size([815, 1, 64, 64])\n",
      "4096\n",
      "2\n",
      "0\n",
      "Variable containing:\n",
      " 116.1367\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1\n",
      "Variable containing:\n",
      " 115.7406\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2\n",
      "Variable containing:\n",
      " 115.3513\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "torch.Size([815, 1, 10, 10])\n",
      "100\n",
      "3\n",
      "(815, 4096)\n",
      "(815, 100)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e370e7cfb70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_st_ae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/data/gabriel/LVseg/segment_out/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/gabriel/LVseg/LVsegmentation/nn_codes/sparse_ae.py\u001b[0m in \u001b[0;36mtrain_st_ae\u001b[0;34m(model_st_ae, epochs, cache_dir)\u001b[0m\n\u001b[1;32m    717\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     scipy.misc.imsave('/data/gabriel/LVseg/segment_out/res_at_3/'+str(j)+'_'+str(i)+'.png',\n\u001b[0;32m--> 719\u001b[0;31m                                       \u001b[0mout_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m                                      )\n\u001b[1;32m    721\u001b[0m                     scipy.misc.imsave('/data/gabriel/LVseg/segment_out/resin_at_3/'+str(j)+'_'+str(i)+'.png',\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "train_st_ae(m,30,'/data/gabriel/LVseg/segment_out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      " 6.9187e-03 -1.1915e-02  5.8215e-03  ...  -1.4894e-02  6.0551e-03  1.0761e-02\n",
      " 8.7572e-03  3.8746e-03 -3.3292e-03  ...  -2.6907e-04 -6.4957e-04  1.2621e-02\n",
      " 5.7839e-03 -3.1909e-03 -1.1649e-02  ...  -1.1631e-02 -1.0435e-02  6.1058e-03\n",
      "                ...                   ⋱                   ...                \n",
      " 1.0588e-02 -1.3649e-02 -9.5096e-03  ...  -1.4259e-02 -2.9642e-03  8.8550e-03\n",
      "-1.3886e-02 -9.0413e-03  1.5443e-02  ...   1.1210e-02  7.7564e-03  4.0435e-03\n",
      "-4.3505e-03  8.5162e-05 -1.1923e-02  ...   1.3287e-02 -1.5546e-02 -1.4662e-02\n",
      "[torch.FloatTensor of size 100x4096]\n",
      "\n",
      "Linear (4096 -> 100)\n",
      "Parameter containing:\n",
      "1.00000e-02 *\n",
      "-6.6258 -5.4087 -3.2958  ...  -5.0022  9.1473 -3.7397\n",
      " 9.8690  2.5529 -1.9651  ...   9.1241 -3.0810 -7.3514\n",
      " 2.2675  2.4380  6.9442  ...   1.3177 -6.3251  1.1443\n",
      "          ...             ⋱             ...          \n",
      " 5.0861  2.7613  3.6447  ...   1.0763  4.4914 -0.5266\n",
      " 2.1048  9.3173  0.2011  ...  -8.8459  5.5133 -1.8896\n",
      " 3.2964  9.6887  0.3991  ...   2.0096 -3.3399  2.8674\n",
      "[torch.FloatTensor of size 100x100]\n",
      "\n",
      "Linear (100 -> 100)\n",
      "Parameter containing:\n",
      " 3.2252e-02 -5.9181e-02  9.5852e-02  ...   9.4788e-02 -8.7138e-02  3.2336e-02\n",
      "-7.8923e-02  9.1821e-02  1.5492e-02  ...   1.9065e-02 -9.3236e-02  4.1486e-02\n",
      "-3.4303e-03 -4.1490e-02 -5.5079e-02  ...  -3.5911e-02  4.5860e-02  1.8607e-02\n",
      "                ...                   ⋱                   ...                \n",
      " 2.5188e-02 -6.7240e-02 -5.8089e-02  ...   7.4031e-02  8.5586e-02 -4.7706e-02\n",
      "-5.2909e-02 -5.6951e-02  4.1408e-02  ...  -8.6483e-02 -3.7180e-02 -2.0169e-02\n",
      " 5.2973e-02 -9.5849e-02 -6.4054e-02  ...   2.0241e-02 -6.7597e-02 -9.6838e-02\n",
      "[torch.FloatTensor of size 4096x100]\n",
      "\n",
      "Linear (100 -> 4096)\n"
     ]
    }
   ],
   "source": [
    "for i in m.modules():\n",
    "    if(isinstance(i,nn.Linear)):\n",
    "        \n",
    "        print(i.weight)\n",
    "        i.weight.data= torch.zeros(100,4096)\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackedAE (\n",
      "  (fc1): Linear (4096 -> 100)\n",
      "  (fc2): Linear (100 -> 100)\n",
      "  (fc3): Linear (100 -> 4096)\n",
      ")\n",
      "Linear (4096 -> 100)\n",
      "Linear (100 -> 100)\n",
      "Linear (100 -> 4096)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n",
      "fc3.weight\n",
      "fc3.bias\n"
     ]
    }
   ],
   "source": [
    "for i in m.state_dict().keys():\n",
    "    #try:\n",
    "    print(i)\n",
    "    #print(type(m.state_dict()[i].size()[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#m.state_dict()['fc1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([[m.state_dict()['fc'+str(i)+'.weight'].size()[0],m.state_dict()['fc'+str(i)+'.weight'].size()[1]] for i in range(1,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Variable(torch.Tensor(815,1,64,64).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear (4096 -> 100)\n",
      "Variable containing:\n",
      " 0.4997  0.4997  0.4980  ...   0.4952  0.4957  0.4974\n",
      " 0.4997  0.4997  0.4980  ...   0.4952  0.4957  0.4974\n",
      " 0.4997  0.4997  0.4980  ...   0.4952  0.4957  0.4974\n",
      "          ...             ⋱             ...          \n",
      " 0.4997  0.4997  0.4980  ...   0.4952  0.4957  0.4974\n",
      " 0.4997  0.4997  0.4980  ...   0.4952  0.4957  0.4974\n",
      " 0.4997  0.4997  0.4980  ...   0.4952  0.4957  0.4974\n",
      "[torch.cuda.FloatTensor of size 815x100 (GPU 1)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count = -1\n",
    "L = 1\n",
    "\n",
    "for i in m.modules():\n",
    "    count+=1\n",
    "    #try:\n",
    "    if(count==L):\n",
    "        #print(tt)\n",
    "        print(i)\n",
    "\n",
    "        print(torch.nn.functional.sigmoid(i(a.view(-1,4096))))\n",
    "\n",
    "    #except:\n",
    "    #   continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "Variable containing:\n",
      " 348.4460\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1\n",
      "Variable containing:\n",
      " 219.3002\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2\n",
      "Variable containing:\n",
      " 244.6627\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "torch.Size([815, 1, 64, 64])\n",
      "4096\n",
      "2\n",
      "0\n",
      "Variable containing:\n",
      " 110.8868\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "1\n",
      "Variable containing:\n",
      " 110.7481\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "2\n",
      "Variable containing:\n",
      " 110.6095\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "torch.Size([815, 1, 64, 64])\n",
      "100\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size '[815 x 100]' is invalid for input of with 3338240 elements at /b/wheel/pytorch-src/torch/lib/TH/THStorage.c:59",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e370e7cfb70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_st_ae\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/data/gabriel/LVseg/segment_out/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/data/gabriel/LVseg/LVsegmentation/nn_codes/sparse_ae.py\u001b[0m in \u001b[0;36mtrain_st_ae\u001b[0;34m(model_st_ae, epochs, cache_dir)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msae_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_at_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msae_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_in\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mview\u001b[0;34m(self, *sizes)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mView\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mview_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_shared_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size '[815 x 100]' is invalid for input of with 3338240 elements at /b/wheel/pytorch-src/torch/lib/TH/THStorage.c:59"
     ]
    }
   ],
   "source": [
    "train_st_ae(m,30,'/data/gabriel/LVseg/segment_out/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# nn_l = localnet(img_path='/data/gabriel/LVseg/dataset_img/img_256/',label_path='/data/gabriel/LVseg/dataset_img/label_256/',b_size=999,test_fraction=0.1,lr = 0.01,gpu=1)\n",
    "                        \n",
    "# with open('/data/gabriel/LVseg/5000_Training.p','rb') as ff:\n",
    "#     [w,b] = pickle.load(ff)\n",
    "# for p in nn_l.modules():\n",
    "#     if isinstance(p,nn.Conv2d):\n",
    "#         #print(p.weight.data)\n",
    "#         #print(p.bias.data)\n",
    "#         p.weight.data, p.bias.data= w.view(100,1,11,11),b\n",
    "#         break\n",
    "# train_lnet(model=nn_l,epochs=1000,fname = './mmm3/mm.pth.tar',pretrain=True,save_dir='./mmm3')\n",
    "# test_lnet(model=nn_l,fname='./mmm3/mm.pth.tar',save_dir='./mmm3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "seg = StackedAE(img_path = '/data/gabriel/LVseg/cropped/img',label_path = '/data/gabriel/LVseg/cropped/label',lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im = plt.imread('/data/gabriel/LVseg/cropped/img/DET0040201_SA9_ph2.png')\n",
    "std = im.std()\n",
    "mn = im.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im-=mn\n",
    "im/=std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "im1 = scipy.misc.imresize(im,(64,64)).astype(float)\n",
    "from torchvision import datasets,transforms\n",
    "seg = seg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "out,out1,out2 = seg(Variable(torch.Tensor(im1.reshape(64,64)).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "aaa = out.cpu().data.numpy().reshape(64,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(aaa),plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P27",
   "language": "python",
   "name": "p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
